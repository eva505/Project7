{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443abf5f",
   "metadata": {},
   "source": [
    " # Project 7 - Implémentation d'un Modèle de Scoring\n",
    " \n",
    "## Part 2 of XX - Entraînement des Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a692d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1. Kaggle Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e933ad",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Data:**\n",
    "* https://www.kaggle.com/c/home-credit-default-risk/data\n",
    "\n",
    "**Series of Notebooks detailing the Problem:**\n",
    "* https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction\n",
    "* https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering\n",
    "* https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering-p2\n",
    "* ...\n",
    "\n",
    "**EDA:**\n",
    "* https://www.kaggle.com/gpreda/home-credit-default-risk-extensive-eda\n",
    "\n",
    "**Feature Engineering:**\n",
    "* https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features\n",
    "\n",
    "**Models/Scripts - Light_GBM**\n",
    "* https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "* https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm\n",
    "\n",
    "**DNN:**\n",
    "https://www.kaggle.com/shep312/deep-learning-in-tf-with-upsampling-lb-758"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b897b8f",
   "metadata": {},
   "source": [
    "# 2. Imports Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0857a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c9fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import win32com.client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc42add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c092fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, balanced_accuracy_score \n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc8725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530bba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7400c7a0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3. Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6681221",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.0 Import des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca9fa21",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_shortcut_path(filepath):\n",
    "    shell = win32com.client.Dispatch(\"WScript.Shell\")\n",
    "    shortcut = shell.CreateShortCut(filepath)\n",
    "    return shortcut.Targetpath +'\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c23c20",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3.1 Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3402d279",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "infinity_transformer = FunctionTransformer(lambda x : x.replace(np.inf, np.nan).replace(-np.inf, np.nan),check_inverse = False)\n",
    "\n",
    "logscale_transformer = FunctionTransformer(np.log, inverse_func = np.exp, check_inverse = False)\n",
    "log1pscale_transformer = FunctionTransformer(np.log1p, inverse_func = np.expm1, check_inverse = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce089072",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3.2 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0425a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gridsearch_evaluation(X_train, y_train, pipeline, param_grid, refit= None, scoring= None, **kwargs) :\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, param_grid, refit=refit, scoring=scoring, **kwargs)\n",
    "                        \n",
    "    grid.fit(X_train, np.ravel((y_train)))\n",
    "    \n",
    "    eval_dict = {}\n",
    "    test_scoring_dict ={}\n",
    "    train_scoring_dict = {}\n",
    "    if refit and scoring:\n",
    "        for i in scoring :\n",
    "            test_scoring_dict[i] = (grid.cv_results_[\"mean_test_\" + i][grid.best_index_], \n",
    "                                    grid.cv_results_[\"std_test_\" + i][grid.best_index_])\n",
    "            train_scoring_dict[i] = (grid.cv_results_[\"mean_train_\" + i][grid.best_index_], \n",
    "                                     grid.cv_results_[\"std_train_\" + i][grid.best_index_])\n",
    "\n",
    "        train_time = (grid.cv_results_[\"mean_fit_time\"][grid.best_index_],\n",
    "                      grid.cv_results_[\"std_fit_time\"][grid.best_index_])\n",
    "\n",
    "        eval_dict = {'estimator' : grid.best_estimator_,\n",
    "                     'eval_method' : 'grid',\n",
    "                     'best_grid_params' : grid.best_params_,\n",
    "                     'train_scores' : train_scoring_dict, \n",
    "                     'test_scores' : test_scoring_dict, \n",
    "                     'train_time' : train_time }\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf449c88",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def output_evaluation(model_name):\n",
    "    ''' Function that outputs/prints the information from the dictionnary that collects the data from \n",
    "    the cross_validate or gridseach'''\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(50*\"_\")\n",
    "\n",
    "    key = model_name\n",
    "    print()\n",
    "    print(50*\"-\")\n",
    "    if model_dict[key]['eval_method'] == 'grid' :\n",
    "        print(\"Les meilleurs parameters sont:\")\n",
    "        print(model_dict[key]['best_grid_params'])\n",
    "        print()\n",
    "    for (k1, l1), (k2, l2) in zip(model_dict[key]['train_scores'].items(), model_dict[key]['test_scores'].items()) :\n",
    "        print(f\"Le metric {k1} donne :\")\n",
    "        print(f\"{l1[0]: .2f} +/- {l1[1]: .2f} pour le train sets\")\n",
    "        print(f\"{l2[0]: .2f} +/- {l2[1]: .2f} pour le test sets\")\n",
    "        print(f\"test score / train score :{(l1[0]/l2[0]) : 0.2f}\")\n",
    "        print()\n",
    "    print(f\"Le temps d'entrainement est {(1000 * model_dict[key]['train_time'][0]): .2f} +/-\" + \\\n",
    "                                      f\"{(1000 * model_dict[key]['train_time'][1]): .2f} ms.\")\n",
    "    print(50*\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd267c31",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3.3 Métrices, Collection et Affichage de Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb46f25c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scoring_tple = ('neg_log_loss', 'roc_auc', 'balanced_accuracy', 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d7630ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9051f04",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4. Import Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b410a30",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "DATAFOLDER = '\\\\DataShortcut.lnk'\n",
    "filepath = get_shortcut_path(PATH+DATAFOLDER)\n",
    "filename = 'data_processed.csv'\n",
    "\n",
    "dataset = pd.read_csv(filepath + filename).drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0158ec46",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset['TARGET']\n",
    "X_id = dataset[['SK_ID_CURR']]\n",
    "X = dataset.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "del dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488dc2a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5. Prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65c3bc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.1 Supprimer des features peu peuplées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31df4ab5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 columns with more than 75% missing values\n",
      "After dropping these columns we are left with 741 columns\n"
     ]
    }
   ],
   "source": [
    "# Identify missing values above a given threshold\n",
    "X = X.replace(np.inf, np.nan).replace(-np.inf, np.nan)\n",
    "X_missing = (X.isnull().sum() / len(X)).sort_values(ascending = False)\n",
    "X_missing = X_missing.index[X_missing > 0.75]\n",
    "#Drop the sparsely populated features\n",
    "X = X.drop(columns = X_missing)\n",
    "print('There are %d columns with more than 75%% missing values' % len(X_missing))\n",
    "print(f'After dropping these columns we are left with {len(X.columns)} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6b424",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.2 Classification des Features en Fonction de leur Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f854e8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**zero-one-features**\n",
    "* des valeurs entre 0 et 1\n",
    "\n",
    "**standard-features**\n",
    "* des valeurs en dehors de la [0,1] \n",
    "* skew < 1\n",
    "   \n",
    "**log-features**\n",
    "* des valeurs > 0\n",
    "* skew >=1\n",
    "\n",
    "**log1p-features**\n",
    "* des valeurs >= 0\n",
    "* skew >=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abb08dad",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 327 features that have values  within the range of 0 and 1.\t -> 'zero_one_features'\n",
      "There are 414 features that have values outside the range of 0 and 1.\n"
     ]
    }
   ],
   "source": [
    "to_be_scaled =  ((X.min() < 0) | (X.max() > 1))\n",
    "to_be_scaled = list(to_be_scaled[to_be_scaled == True].index.values)\n",
    "zero_one_features = [col for col in X.columns if col not in to_be_scaled]\n",
    "print(f\"There are {len(zero_one_features)} features that have values  within the range of 0 and 1.\\t -> 'zero_one_features'\")\n",
    "print(f\"There are {len(to_be_scaled)} features that have values outside the range of 0 and 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fe1ecab",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the non 'zero_one_features' there are 92 features with skew  < 1.\t -> 'standard_features'\n",
      "Of the non 'zero_one_features' there are 322 features with skew >= 1.\n"
     ]
    }
   ],
   "source": [
    "#If the skew of the values is greater than 1, we will scale the features with either log or lop1p \n",
    "#and if necessary multiply by -1 beforehand\n",
    "skewed = (X[to_be_scaled].skew() >= 1)\n",
    "skewed = list(skewed[skewed == True].index.values)\n",
    "standard_features = [col for col in to_be_scaled if col not in skewed]\n",
    "print(f\"Of the non 'zero_one_features' there are {len(standard_features)} features with skew  < 1.\\t -> 'standard_features'\")\n",
    "print(f\"Of the non 'zero_one_features' there are {len(skewed)} features with skew >= 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db80b44e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the non 'standard_features' there are 18 features with min  > 0.\t -> 'log_features'\n",
      "Of the non 'standard_features' there are 263 features with min == 0.\t -> 'lop1p_features'\n",
      "Of the non 'standard_features' there are 0 features with max  < 0.\t -> 'neg_log_features'\n",
      "Of the non 'standard_features' there are 0 features with max == 0.\t -> 'neg_lop1p_features'\n"
     ]
    }
   ],
   "source": [
    "log_select = (X[skewed].min() > 0)\n",
    "log_features = list(log_select[log_select == True].index.values)\n",
    "log1p_select = (X[skewed].min() == 0)\n",
    "log1p_features = list(log1p_select[log1p_select == True].index.values)\n",
    "neg_log_select = (X[skewed].max() < 0)\n",
    "neg_log_features = list(neg_log_select[neg_log_select == True].index.values)\n",
    "neg_log1p_select = (X[skewed].max() == 0)\n",
    "neg_log1p_features = list(neg_log1p_select[neg_log1p_select == True].index.values)\n",
    "print(f\"Of the non 'standard_features' there are {len(log_features)} features with min  > 0.\\t -> 'log_features'\")\n",
    "print(f\"Of the non 'standard_features' there are {len(log1p_features)} features with min == 0.\\t -> 'lop1p_features'\")\n",
    "print(f\"Of the non 'standard_features' there are {len(neg_log_features)} features with max  < 0.\\t -> 'neg_log_features'\")\n",
    "print(f\"Of the non 'standard_features' there are {len(neg_log1p_features)} features with max == 0.\\t -> 'neg_lop1p_features'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a9a6593",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41 non 'standard_features' that cannot easily be transformed to a logscale.\t -> 'robustscale_features'\n"
     ]
    }
   ],
   "source": [
    "robustscale_features = [col for col in skewed if col not in log_features+log1p_features]\n",
    "print(f\"There are {len(robustscale_features)} non 'standard_features' that cannot easily \\\n",
    "be transformed to a logscale.\\t -> 'robustscale_features'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46533db1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### APPL_CNT_CHILDREN / APPL_CNT_FAM_MEMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e05dc650",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     215371\n",
       "1      61119\n",
       "2      26749\n",
       "3       3717\n",
       "4        429\n",
       "5         84\n",
       "6         21\n",
       "7          7\n",
       "14         3\n",
       "8          2\n",
       "9          2\n",
       "12         2\n",
       "10         2\n",
       "19         2\n",
       "11         1\n",
       "Name: APPL_CNT_CHILDREN, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['APPL_CNT_CHILDREN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "894061a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "select = X['APPL_CNT_CHILDREN'] >= 5\n",
    "X.loc[select, 'APPL_CNT_CHILDREN'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f427dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "select = X['APPL_CNT_FAM_MEMBERS'] >= 7\n",
    "X.loc[select, 'APPL_CNT_FAM_MEMBERS'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1791b2",
   "metadata": {},
   "source": [
    "# 6. Train/Test Dévision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09d4565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "seed = 33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = seed, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f111c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 7. Les Données Déséquilibrées (test des méthodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eebe40e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24825 clients in the dataset defaulted, 282686 did not.\n",
      "That's 8.78%.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(X[y==1])} clients in the dataset defaulted, {len(X[y==0])} did not.\")\n",
    "print(f\"That's {round(100*len(X[y==1])/len(X[y==0]), 2)}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e182dd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 7.1 Sous-échantillonnage de la classe majoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60640b4a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215257, 741) (34754, 741) (34754,) 17377\n",
      "(215257, 741) (34754, 741) (34754,) 17377\n"
     ]
    }
   ],
   "source": [
    "undersample = True\n",
    "min_size = len(X_train[y_train==1])\n",
    "if undersample :\n",
    "    #undersample manually\n",
    "    select = list(X_train[y_train==0].sample(min_size, random_state=22).index.values) + list(X_train[y_train==1].index.values)\n",
    "    X_under = X_train.loc[select, :]\n",
    "    y_under = y_train.loc[select]\n",
    "    print(X_train.shape, X_under.shape, y_under.shape, min_size)\n",
    "    #undersample with the module SMOTE\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_under, y_under = rus.fit_resample(X_train, y_train)\n",
    "    print(X_train.shape, X_under.shape, y_under.shape, min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49604a5c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clear the memory\n",
    "del X_under, y_under, rus\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d41e4c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 7.2 Suréchantillonnage de la classe minoritaire avec me Module SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "894a0606",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215257, 741) (395760, 741) (395760,) 197880\n"
     ]
    }
   ],
   "source": [
    "oversample = True\n",
    "max_size = len(X_train[y_train==0])\n",
    "if oversample :    \n",
    "    #oversample with the module SMOTE\n",
    "    imputer = SimpleImputer()\n",
    "    X_imp = imputer.fit_transform(X_train)\n",
    "    smote = SMOTE()\n",
    "    X_over, y_over = smote.fit_resample(X_imp, y_train)\n",
    "    print(X_train.shape, X_over.shape, y_over.shape, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "265bb5f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clear the memory\n",
    "del X_over, y_over, imputer, smote\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e579c3de",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 8. Le Préprocesseur (mise à l'échelle des features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d242477",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le préprocesseur est concu d'une telle façon que s'il rencontre des colonnes/features inconnues, il va les simplement écarter (remainder = 'drop')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fc1ce19",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers = [  \n",
    "                                                 ('zero_one', 'passthrough', zero_one_features),\n",
    "                                                 ('logscale', Pipeline([('log', logscale_transformer),\n",
    "                                                                        ('standard', MinMaxScaler())]), \n",
    "                                                              log_features),\n",
    "                                                 ('log1pscale', Pipeline([('log1p', log1pscale_transformer),\n",
    "                                                                          ('standard', MinMaxScaler())]), \n",
    "                                                               log1p_features),\n",
    "                                                 ('standardscale', MinMaxScaler(), standard_features),\n",
    "                                                 ('robustscale', MinMaxScaler(), robustscale_features),\n",
    "                                                         \n",
    "                                                ], remainder = 'drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64e84c20",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('zero_one', 'passthrough',\n",
       "                                 ['APPL_NAME_CONTRACT_TYPE', 'APPL_CODE_GENDER',\n",
       "                                  'APPL_FLAG_OWN_CAR', 'APPL_FLAG_OWN_REALTY',\n",
       "                                  'APPL_REGION_POPULATION_RELATIVE',\n",
       "                                  'APPL_FLAG_MOBIL', 'APPL_FLAG_EMP_PHONE',\n",
       "                                  'APPL_FLAG_WORK_PHONE',\n",
       "                                  'APPL_FLAG_CONT_MOBILE', 'APPL_FLAG_PHONE',\n",
       "                                  'APPL_FLAG_EMAIL',\n",
       "                                  'APPL_REG_REGION_NOT_LIVE_REGION',\n",
       "                                  'APPL_REG_RE...\n",
       "                                  'INSTAL_NEW_PAYMENT_DIFF_MAX',\n",
       "                                  'BURO_DAYS_CREDIT_ENDDATE_MIN',\n",
       "                                  'BURO_DAYS_CREDIT_ENDDATE_MAX',\n",
       "                                  'BURO_DAYS_CREDIT_ENDDATE_MEAN',\n",
       "                                  'BURO_AMT_CREDIT_SUM_DEBT_MAX',\n",
       "                                  'BURO_AMT_CREDIT_SUM_DEBT_MEAN',\n",
       "                                  'BURO_AMT_CREDIT_SUM_DEBT_SUM',\n",
       "                                  'BURO_AMT_CREDIT_SUM_LIMIT_MEAN',\n",
       "                                  'BURO_AMT_CREDIT_SUM_LIMIT_SUM',\n",
       "                                  'ACTIVE_DAYS_CREDIT_ENDDATE_MIN',\n",
       "                                  'ACTIVE_DAYS_CREDIT_ENDDATE_MAX', ...])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3272a2",
   "metadata": {},
   "source": [
    "# 9. Les Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f580877",
   "metadata": {},
   "source": [
    "## 9.1 LogisticRegression - Version0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a95bb5",
   "metadata": {},
   "source": [
    "### 9.1.1 Paramètres du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afd71fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'LogRegr0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "221bf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                     ('preprocessor', MinMaxScaler()),\n",
    "                     ('imputer', SimpleImputer()),\n",
    "                     ('model', LogisticRegression(tol=1e-2, solver='saga', warm_start=True)),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfb61aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'imputer__strategy' : ['median'],\n",
    "              'model__class_weight' : ['balanced'],\n",
    "              'model__C' : [2.5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbaaaff",
   "metadata": {},
   "source": [
    "### 9.1.2 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fce3cbde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END imputer__strategy=median, model__C=2.5, model__class_weight=balanced; balanced_accuracy: (train=0.711, test=0.704) f1: (train=0.282, test=0.277) neg_log_loss: (train=-0.573, test=-0.577) roc_auc: (train=0.781, test=0.773) total time= 1.4min\n",
      "[CV 2/5] END imputer__strategy=median, model__C=2.5, model__class_weight=balanced; balanced_accuracy: (train=0.708, test=0.706) f1: (train=0.264, test=0.263) neg_log_loss: (train=-0.637, test=-0.640) roc_auc: (train=0.781, test=0.776) total time= 1.2min\n",
      "[CV 3/5] END imputer__strategy=median, model__C=2.5, model__class_weight=balanced; balanced_accuracy: (train=0.711, test=0.701) f1: (train=0.289, test=0.281) neg_log_loss: (train=-0.549, test=-0.553) roc_auc: (train=0.782, test=0.771) total time= 1.3min\n",
      "[CV 4/5] END imputer__strategy=median, model__C=2.5, model__class_weight=balanced; balanced_accuracy: (train=0.712, test=0.702) f1: (train=0.276, test=0.270) neg_log_loss: (train=-0.598, test=-0.599) roc_auc: (train=0.783, test=0.769) total time= 1.2min\n",
      "[CV 5/5] END imputer__strategy=median, model__C=2.5, model__class_weight=balanced; balanced_accuracy: (train=0.711, test=0.701) f1: (train=0.281, test=0.274) neg_log_loss: (train=-0.575, test=-0.579) roc_auc: (train=0.783, test=0.769) total time=  57.8s\n"
     ]
    }
   ],
   "source": [
    "eval_dict = gridsearch_evaluation(X_train, y_train, pipeline, param_grid, scoring = scoring_tple,\n",
    "                                  return_train_score = True, refit='roc_auc', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93e81db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[modelname] = eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf392ae8",
   "metadata": {},
   "source": [
    "### 9.1.3 Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "656c741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogRegr0\n",
      "__________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Les meilleurs parameters sont:\n",
      "{'imputer__strategy': 'median', 'model__C': 2.5, 'model__class_weight': 'balanced'}\n",
      "\n",
      "Le metric neg_log_loss donne :\n",
      "-0.59 +/-  0.03 pour le train sets\n",
      "-0.59 +/-  0.03 pour le test sets\n",
      "test score / train score : 0.99\n",
      "\n",
      "Le metric roc_auc donne :\n",
      " 0.78 +/-  0.00 pour le train sets\n",
      " 0.77 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.01\n",
      "\n",
      "Le metric balanced_accuracy donne :\n",
      " 0.71 +/-  0.00 pour le train sets\n",
      " 0.70 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.01\n",
      "\n",
      "Le metric f1 donne :\n",
      " 0.28 +/-  0.01 pour le train sets\n",
      " 0.27 +/-  0.01 pour le test sets\n",
      "test score / train score : 1.02\n",
      "\n",
      "Le temps d'entrainement est  69851.38 +/- 7859.61 ms.\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_evaluation(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14084fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = model_dict[modelname]['estimator']\n",
    "y_test_pred = estimator.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63358479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss score for the X_test set is\t 0.5767973231104543\n",
      "The ROC AUC score for the X_test set is\t\t 0.7706364390573563\n",
      "The bal. accuracy score for the X_test set is\t 0.7035541967864838\n",
      "The f1 score for the X_test set is\t\t 0.2760337508516325\n"
     ]
    }
   ],
   "source": [
    "print(f'The log loss score for the X_test set is\\t {log_loss(y_test, y_test_pred)}')\n",
    "print(f'The ROC AUC score for the X_test set is\\t\\t {roc_auc_score(y_test, y_test_pred[:,1])}')\n",
    "print(f'The bal. accuracy score for the X_test set is\\t {balanced_accuracy_score(y_test, y_test_pred[:,1].round())}')\n",
    "print(f'The f1 score for the X_test set is\\t\\t {f1_score(y_test, y_test_pred[:,1].round())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b2593",
   "metadata": {},
   "source": [
    "### 9.1.4 Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f31b30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "export = False\n",
    "if export:\n",
    "    PATH = os.path.dirname(os.getcwd()) \n",
    "    DATAFOLDER = '\\\\Data\\\\'\n",
    "    estimator = model_dict[modelname]['estimator']\n",
    "    joblib.dump(estimator, PATH + DATAFOLDER + modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f131a32",
   "metadata": {},
   "source": [
    "## 9.2 LogisticRegression - Version1 (avec SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e474dbd",
   "metadata": {},
   "source": [
    "### 9.2.1 Paramètres du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5395e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'LogRegr1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bef59779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('preprocessor', MinMaxScaler()),\n",
    "                     ('imputer', SimpleImputer()),\n",
    "                     ('smote', SMOTE()),\n",
    "                     ('model', LogisticRegression(tol=1e-2, solver='saga', warm_start=True))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "513b726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'imputer__strategy' : ['median'],\n",
    "              'model__C' : [0.1, 1, 2.5, 5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fee468",
   "metadata": {},
   "source": [
    "### 9.2.2 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e3c6221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.550, test=-0.553) roc_auc: (train=0.763, test=0.758) total time=  54.4s\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.549, test=-0.551) roc_auc: (train=0.763, test=0.759) total time=  56.4s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.549, test=-0.552) roc_auc: (train=0.764, test=0.756) total time=  54.5s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.547, test=-0.550) roc_auc: (train=0.765, test=0.753) total time=  54.7s\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.549, test=-0.553) roc_auc: (train=0.765, test=0.752) total time=  53.1s\n",
      "[CV 1/5] END imputer__strategy=median, model__C=1; neg_log_loss: (train=-0.547, test=-0.550) roc_auc: (train=0.767, test=0.760) total time= 1.8min\n",
      "[CV 2/5] END imputer__strategy=median, model__C=1; neg_log_loss: (train=-0.545, test=-0.548) roc_auc: (train=0.767, test=0.761) total time= 1.7min\n",
      "[CV 3/5] END imputer__strategy=median, model__C=1; neg_log_loss: (train=-0.546, test=-0.552) roc_auc: (train=0.768, test=0.758) total time= 1.7min\n",
      "[CV 4/5] END imputer__strategy=median, model__C=1; neg_log_loss: (train=-0.544, test=-0.548) roc_auc: (train=0.768, test=0.756) total time= 1.7min\n",
      "[CV 5/5] END imputer__strategy=median, model__C=1; neg_log_loss: (train=-0.545, test=-0.550) roc_auc: (train=0.769, test=0.754) total time= 1.5min\n",
      "[CV 1/5] END imputer__strategy=median, model__C=2.5; neg_log_loss: (train=-0.545, test=-0.549) roc_auc: (train=0.767, test=0.760) total time= 2.0min\n",
      "[CV 2/5] END imputer__strategy=median, model__C=2.5; neg_log_loss: (train=-0.545, test=-0.549) roc_auc: (train=0.767, test=0.762) total time= 1.9min\n",
      "[CV 3/5] END imputer__strategy=median, model__C=2.5; neg_log_loss: (train=-0.545, test=-0.551) roc_auc: (train=0.768, test=0.758) total time= 2.0min\n",
      "[CV 4/5] END imputer__strategy=median, model__C=2.5; neg_log_loss: (train=-0.545, test=-0.549) roc_auc: (train=0.769, test=0.756) total time= 1.9min\n",
      "[CV 5/5] END imputer__strategy=median, model__C=2.5; neg_log_loss: (train=-0.546, test=-0.551) roc_auc: (train=0.769, test=0.754) total time= 1.6min\n",
      "[CV 1/5] END imputer__strategy=median, model__C=5; neg_log_loss: (train=-0.546, test=-0.550) roc_auc: (train=0.767, test=0.760) total time= 2.2min\n",
      "[CV 2/5] END imputer__strategy=median, model__C=5; neg_log_loss: (train=-0.545, test=-0.549) roc_auc: (train=0.768, test=0.762) total time= 2.0min\n",
      "[CV 3/5] END imputer__strategy=median, model__C=5; neg_log_loss: (train=-0.546, test=-0.552) roc_auc: (train=0.769, test=0.759) total time= 2.1min\n",
      "[CV 4/5] END imputer__strategy=median, model__C=5; neg_log_loss: (train=-0.546, test=-0.549) roc_auc: (train=0.769, test=0.757) total time= 2.0min\n",
      "[CV 5/5] END imputer__strategy=median, model__C=5; neg_log_loss: (train=-0.545, test=-0.551) roc_auc: (train=0.769, test=0.754) total time= 1.7min\n"
     ]
    }
   ],
   "source": [
    "eval_dict = gridsearch_evaluation(X_train, y_train, pipeline, param_grid, scoring = ('neg_log_loss', 'roc_auc'),\n",
    "                                  return_train_score = True, refit='roc_auc', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44b71792",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[modelname] = eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8fba70",
   "metadata": {},
   "source": [
    "### 9.2.3 Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e723203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogRegr1\n",
      "__________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Les meilleurs parameters sont:\n",
      "{'imputer__strategy': 'median', 'model__C': 5}\n",
      "\n",
      "Le metric neg_log_loss donne :\n",
      "-0.55 +/-  0.00 pour le train sets\n",
      "-0.55 +/-  0.00 pour le test sets\n",
      "test score / train score : 0.99\n",
      "\n",
      "Le metric roc_auc donne :\n",
      " 0.77 +/-  0.00 pour le train sets\n",
      " 0.76 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.01\n",
      "\n",
      "Le temps d'entrainement est  118407.62 +/- 9333.24 ms.\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_evaluation(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563e952",
   "metadata": {},
   "source": [
    "### 9.2.4 Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "export = False\n",
    "if export:\n",
    "    PATH = os.path.dirname(os.getcwd()) \n",
    "    DATAFOLDER = '\\\\Data\\\\'\n",
    "    estimator = model_dict[modelname]['estimator']\n",
    "    joblib.dump(estimator, PATH + DATAFOLDER + modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632ca4c",
   "metadata": {},
   "source": [
    "## 9.3 LogisticRegression - Version2 (avec un preprocessor customisé)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b82f0e",
   "metadata": {},
   "source": [
    "### 9.3.1 Paramètres du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ffd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'LogRegr2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "276d47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                     ('preprocessor', preprocessor),\n",
    "                     ('imputer', SimpleImputer()),\n",
    "                     ('model', LogisticRegression(tol=1e-2, solver='saga', warm_start=True))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "490bf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'imputer__strategy' : ['median'],\n",
    "              'model__class_weight' : ['balanced'],\n",
    "              'model__C' : [0.01, 0.05, 0.1, 0.15]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3bb51a",
   "metadata": {},
   "source": [
    "### 9.3.2 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "090bec5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.01, model__class_weight=balanced; neg_log_loss: (train=-0.575, test=-0.575) roc_auc: (train=0.778, test=0.777) total time=  40.7s\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.01, model__class_weight=balanced; neg_log_loss: (train=-0.565, test=-0.566) roc_auc: (train=0.778, test=0.776) total time=  40.7s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.01, model__class_weight=balanced; neg_log_loss: (train=-0.567, test=-0.569) roc_auc: (train=0.779, test=0.772) total time=  37.1s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.01, model__class_weight=balanced; neg_log_loss: (train=-0.562, test=-0.562) roc_auc: (train=0.779, test=0.769) total time=  38.5s\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.01, model__class_weight=balanced; neg_log_loss: (train=-0.561, test=-0.564) roc_auc: (train=0.780, test=0.770) total time=  36.7s\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.05, model__class_weight=balanced; neg_log_loss: (train=-0.562, test=-0.563) roc_auc: (train=0.782, test=0.779) total time=  38.3s\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.05, model__class_weight=balanced; neg_log_loss: (train=-0.583, test=-0.585) roc_auc: (train=0.782, test=0.778) total time=  41.2s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.05, model__class_weight=balanced; neg_log_loss: (train=-0.574, test=-0.577) roc_auc: (train=0.783, test=0.775) total time=  37.3s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.05, model__class_weight=balanced; neg_log_loss: (train=-0.567, test=-0.568) roc_auc: (train=0.784, test=0.772) total time=  41.5s\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.05, model__class_weight=balanced; neg_log_loss: (train=-0.550, test=-0.555) roc_auc: (train=0.784, test=0.771) total time=  37.3s\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.1, model__class_weight=balanced; neg_log_loss: (train=-0.567, test=-0.569) roc_auc: (train=0.783, test=0.779) total time=  47.3s\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.1, model__class_weight=balanced; neg_log_loss: (train=-0.511, test=-0.514) roc_auc: (train=0.783, test=0.779) total time=  45.6s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.1, model__class_weight=balanced; neg_log_loss: (train=-0.560, test=-0.563) roc_auc: (train=0.784, test=0.775) total time=  46.6s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.1, model__class_weight=balanced; neg_log_loss: (train=-0.570, test=-0.571) roc_auc: (train=0.785, test=0.772) total time=  52.3s\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.1, model__class_weight=balanced; neg_log_loss: (train=-0.589, test=-0.595) roc_auc: (train=0.785, test=0.771) total time=  47.2s\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.15, model__class_weight=balanced; neg_log_loss: (train=-0.583, test=-0.585) roc_auc: (train=0.784, test=0.779) total time=  55.0s\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.15, model__class_weight=balanced; neg_log_loss: (train=-0.584, test=-0.586) roc_auc: (train=0.784, test=0.779) total time=  53.4s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.15, model__class_weight=balanced; neg_log_loss: (train=-0.489, test=-0.492) roc_auc: (train=0.785, test=0.776) total time=  53.4s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.15, model__class_weight=balanced; neg_log_loss: (train=-0.570, test=-0.570) roc_auc: (train=0.785, test=0.773) total time= 1.1min\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.15, model__class_weight=balanced; neg_log_loss: (train=-0.437, test=-0.442) roc_auc: (train=0.786, test=0.770) total time=  51.7s\n"
     ]
    }
   ],
   "source": [
    "eval_dict = gridsearch_evaluation(X_train, y_train, pipeline, param_grid, scoring = scoring_tple,\n",
    "                                  return_train_score = True, refit='roc_auc', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3a02d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[modelname] = eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2751476",
   "metadata": {},
   "source": [
    "### 9.3.4 Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c27a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogRegr2\n",
      "__________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Les meilleurs parameters sont:\n",
      "{'imputer__strategy': 'median', 'model__C': 0.15, 'model__class_weight': 'balanced'}\n",
      "\n",
      "Le metric neg_log_loss donne :\n",
      "-0.53 +/-  0.06 pour le train sets\n",
      "-0.54 +/-  0.06 pour le test sets\n",
      "test score / train score : 0.99\n",
      "\n",
      "Le metric roc_auc donne :\n",
      " 0.78 +/-  0.00 pour le train sets\n",
      " 0.78 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.01\n",
      "\n",
      "Le temps d'entrainement est  53905.45 +/- 4647.00 ms.\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_evaluation(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53537f57",
   "metadata": {},
   "source": [
    "### 9.3.4 Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "export = False\n",
    "if export:\n",
    "    PATH = os.path.dirname(os.getcwd()) \n",
    "    DATAFOLDER = '\\\\Data\\\\'\n",
    "    estimator = model_dict[modelname]['estimator']\n",
    "    joblib.dump(estimator, PATH + DATAFOLDER + modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f1bf9",
   "metadata": {},
   "source": [
    "## 9.4 LogisticRegression - Version3 (avec preprocessor customisé, PCA et SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98e99e",
   "metadata": {},
   "source": [
    "### 9.4.1 Paramètres du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ae08cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'LogRegr3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97bfdf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('imputer', SimpleImputer()),\n",
    "                     ('pca', PCA(0.99)),\n",
    "                     ('smote', SMOTE()),\n",
    "                     ('model', LogisticRegression(tol=1e-2, solver='saga', warm_start=True))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa1bb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'imputer__strategy' : ['median'],\n",
    "              'model__C' : [0.005, 0.1, 0.2, 0.5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14653dc",
   "metadata": {},
   "source": [
    "### 9.4.2 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fec264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.005; neg_log_loss: (train=-0.555, test=-0.553) roc_auc: (train=0.759, test=0.760) total time=  54.9s\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.005; neg_log_loss: (train=-0.555, test=-0.556) roc_auc: (train=0.760, test=0.758) total time=  55.7s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.005; neg_log_loss: (train=-0.554, test=-0.557) roc_auc: (train=0.760, test=0.757) total time=  55.6s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.005; neg_log_loss: (train=-0.554, test=-0.556) roc_auc: (train=0.761, test=0.751) total time=  54.6s\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.005; neg_log_loss: (train=-0.553, test=-0.557) roc_auc: (train=0.761, test=0.751) total time=  54.8s\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.554, test=-0.553) roc_auc: (train=0.760, test=0.759) total time=  56.5s\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.552, test=-0.554) roc_auc: (train=0.761, test=0.758) total time=  54.5s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.552, test=-0.555) roc_auc: (train=0.761, test=0.757) total time=  54.5s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.552, test=-0.554) roc_auc: (train=0.761, test=0.753) total time=  55.5s\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.1; neg_log_loss: (train=-0.552, test=-0.557) roc_auc: (train=0.762, test=0.751) total time=  54.6s\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.2; neg_log_loss: (train=-0.554, test=-0.553) roc_auc: (train=0.760, test=0.758) total time= 1.0min\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.2; neg_log_loss: (train=-0.553, test=-0.555) roc_auc: (train=0.761, test=0.758) total time=  57.6s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.2; neg_log_loss: (train=-0.553, test=-0.556) roc_auc: (train=0.761, test=0.757) total time=  56.7s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.2; neg_log_loss: (train=-0.552, test=-0.554) roc_auc: (train=0.762, test=0.753) total time=  55.6s\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.2; neg_log_loss: (train=-0.551, test=-0.557) roc_auc: (train=0.762, test=0.750) total time=  55.4s\n",
      "[CV 1/5] END imputer__strategy=median, model__C=0.5; neg_log_loss: (train=-0.554, test=-0.553) roc_auc: (train=0.760, test=0.758) total time=  56.8s\n",
      "[CV 2/5] END imputer__strategy=median, model__C=0.5; neg_log_loss: (train=-0.553, test=-0.556) roc_auc: (train=0.761, test=0.757) total time=  55.8s\n",
      "[CV 3/5] END imputer__strategy=median, model__C=0.5; neg_log_loss: (train=-0.553, test=-0.556) roc_auc: (train=0.761, test=0.757) total time=  56.9s\n",
      "[CV 4/5] END imputer__strategy=median, model__C=0.5; neg_log_loss: (train=-0.552, test=-0.554) roc_auc: (train=0.761, test=0.753) total time=  54.6s\n",
      "[CV 5/5] END imputer__strategy=median, model__C=0.5; neg_log_loss: (train=-0.552, test=-0.557) roc_auc: (train=0.762, test=0.750) total time=  56.3s\n"
     ]
    }
   ],
   "source": [
    "eval_dict = gridsearch_evaluation(X_train, y_train, pipeline, param_grid, scoring = scoring_tple,\n",
    "                                  return_train_score = True, refit='roc_auc', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d0ad655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[modelname] = eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae263e",
   "metadata": {},
   "source": [
    "### 9.4.3 Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cdcf1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogRegr3\n",
      "__________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Les meilleurs parameters sont:\n",
      "{'imputer__strategy': 'median', 'model__C': 0.005}\n",
      "\n",
      "Le metric neg_log_loss donne :\n",
      "-0.55 +/-  0.00 pour le train sets\n",
      "-0.56 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.00\n",
      "\n",
      "Le metric roc_auc donne :\n",
      " 0.76 +/-  0.00 pour le train sets\n",
      " 0.76 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.01\n",
      "\n",
      "Le temps d'entrainement est  52645.26 +/- 448.40 ms.\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_evaluation(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128faef9",
   "metadata": {},
   "source": [
    "## 9.5 BalancedRandomForestClassifier (avec preprocessor customisé et PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d3efb",
   "metadata": {},
   "source": [
    "### 9.5.1 Paramètres du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee9bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'BalRandForest1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab7e7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('imputer', SimpleImputer()),\n",
    "                     ('pca', PCA(0.99)),\n",
    "                     ('model', BalancedRandomForestClassifier(random_state=33, verbose=1))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78801692",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'imputer__strategy' : ['median'],\n",
    "              'model__class_weight' : ['balanced'],\n",
    "              'model__n_estimators' : [10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d71e3",
   "metadata": {},
   "source": [
    "### 9.5.2 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "255f22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=10; neg_log_loss: (train=-0.661, test=-0.896) roc_auc: (train=0.939, test=0.592) total time=  60.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=10; neg_log_loss: (train=-0.650, test=-0.870) roc_auc: (train=0.941, test=0.585) total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=10; neg_log_loss: (train=-0.665, test=-0.898) roc_auc: (train=0.938, test=0.594) total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=10; neg_log_loss: (train=-0.653, test=-0.903) roc_auc: (train=0.940, test=0.596) total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=10; neg_log_loss: (train=-0.630, test=-0.884) roc_auc: (train=0.941, test=0.592) total time=  59.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=100; neg_log_loss: (train=-0.509, test=-0.599) roc_auc: (train=0.988, test=0.614) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=100; neg_log_loss: (train=-0.508, test=-0.600) roc_auc: (train=0.988, test=0.611) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=100; neg_log_loss: (train=-0.508, test=-0.599) roc_auc: (train=0.988, test=0.621) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=100; neg_log_loss: (train=-0.506, test=-0.601) roc_auc: (train=0.988, test=0.617) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END imputer__strategy=median, model__class_weight=balanced, model__n_estimators=100; neg_log_loss: (train=-0.507, test=-0.601) roc_auc: (train=0.988, test=0.613) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "eval_dict = gridsearch_evaluation(X_train, y_train, pipeline, param_grid, scoring = scoring_tple,\n",
    "                                  return_train_score = True, refit='roc_auc', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1459183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[modelname] = eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666dad8f",
   "metadata": {},
   "source": [
    "### 9.5.3 Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "717d7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BalRandForest1\n",
      "__________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Les meilleurs parameters sont:\n",
      "{'imputer__strategy': 'median', 'model__class_weight': 'balanced', 'model__n_estimators': 100}\n",
      "\n",
      "Le metric neg_log_loss donne :\n",
      "-0.51 +/-  0.00 pour le train sets\n",
      "-0.60 +/-  0.00 pour le test sets\n",
      "test score / train score : 0.85\n",
      "\n",
      "Le metric roc_auc donne :\n",
      " 0.99 +/-  0.00 pour le train sets\n",
      " 0.62 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.61\n",
      "\n",
      "Le temps d'entrainement est  223737.34 +/- 1766.61 ms.\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_evaluation(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b872f",
   "metadata": {},
   "source": [
    "## 9.6 RUSBoostClassifier (avec preprocessor customisé et PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8b5af",
   "metadata": {},
   "source": [
    "### 9.6.1 Paramètres du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'RUSBoost1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b61ad5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('imputer', SimpleImputer()),\n",
    "                     ('pca', PCA(0.99)),\n",
    "                     ('model', RUSBoostClassifier(random_state=33))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d8cf7",
   "metadata": {},
   "source": [
    "### 9.6.2 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5f885a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'imputer__strategy' : ['median'],\n",
    "              'model__n_estimators' : [50],\n",
    "              'model__learning_rate' : [0.25, 0.5, 0.75, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72edd03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END imputer__strategy=median, model__learning_rate=0.25, model__n_estimators=50; neg_log_loss: (train=-0.686, test=-0.686) roc_auc: (train=0.710, test=0.707) total time= 1.9min\n",
      "[CV 2/5] END imputer__strategy=median, model__learning_rate=0.25, model__n_estimators=50; neg_log_loss: (train=-0.686, test=-0.686) roc_auc: (train=0.707, test=0.702) total time= 1.9min\n",
      "[CV 3/5] END imputer__strategy=median, model__learning_rate=0.25, model__n_estimators=50; neg_log_loss: (train=-0.686, test=-0.686) roc_auc: (train=0.711, test=0.704) total time= 1.9min\n",
      "[CV 4/5] END imputer__strategy=median, model__learning_rate=0.25, model__n_estimators=50; neg_log_loss: (train=-0.685, test=-0.686) roc_auc: (train=0.711, test=0.698) total time= 1.9min\n",
      "[CV 5/5] END imputer__strategy=median, model__learning_rate=0.25, model__n_estimators=50; neg_log_loss: (train=-0.686, test=-0.686) roc_auc: (train=0.708, test=0.703) total time= 1.9min\n",
      "[CV 1/5] END imputer__strategy=median, model__learning_rate=0.5, model__n_estimators=50; neg_log_loss: (train=-0.688, test=-0.688) roc_auc: (train=0.725, test=0.719) total time= 2.0min\n",
      "[CV 2/5] END imputer__strategy=median, model__learning_rate=0.5, model__n_estimators=50; neg_log_loss: (train=-0.688, test=-0.688) roc_auc: (train=0.723, test=0.715) total time= 1.9min\n",
      "[CV 3/5] END imputer__strategy=median, model__learning_rate=0.5, model__n_estimators=50; neg_log_loss: (train=-0.688, test=-0.688) roc_auc: (train=0.726, test=0.719) total time= 1.9min\n",
      "[CV 4/5] END imputer__strategy=median, model__learning_rate=0.5, model__n_estimators=50; neg_log_loss: (train=-0.688, test=-0.688) roc_auc: (train=0.728, test=0.713) total time= 1.9min\n",
      "[CV 5/5] END imputer__strategy=median, model__learning_rate=0.5, model__n_estimators=50; neg_log_loss: (train=-0.688, test=-0.688) roc_auc: (train=0.725, test=0.716) total time= 1.9min\n",
      "[CV 1/5] END imputer__strategy=median, model__learning_rate=0.75, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.728, test=0.723) total time= 1.9min\n",
      "[CV 2/5] END imputer__strategy=median, model__learning_rate=0.75, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.726, test=0.715) total time= 1.9min\n",
      "[CV 3/5] END imputer__strategy=median, model__learning_rate=0.75, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.729, test=0.715) total time= 1.9min\n",
      "[CV 4/5] END imputer__strategy=median, model__learning_rate=0.75, model__n_estimators=50; neg_log_loss: (train=-0.688, test=-0.688) roc_auc: (train=0.733, test=0.718) total time= 1.9min\n",
      "[CV 5/5] END imputer__strategy=median, model__learning_rate=0.75, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.729, test=0.717) total time= 1.9min\n",
      "[CV 1/5] END imputer__strategy=median, model__learning_rate=1, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.727, test=0.719) total time= 1.9min\n",
      "[CV 2/5] END imputer__strategy=median, model__learning_rate=1, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.725, test=0.712) total time= 1.9min\n",
      "[CV 3/5] END imputer__strategy=median, model__learning_rate=1, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.727, test=0.718) total time= 1.9min\n",
      "[CV 4/5] END imputer__strategy=median, model__learning_rate=1, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.730, test=0.713) total time= 1.9min\n",
      "[CV 5/5] END imputer__strategy=median, model__learning_rate=1, model__n_estimators=50; neg_log_loss: (train=-0.689, test=-0.689) roc_auc: (train=0.728, test=0.717) total time= 2.0min\n"
     ]
    }
   ],
   "source": [
    "eval_dict = gridsearch_evaluation(X_train, y_train, pipeline, param_grid, scoring = ('neg_log_loss', 'roc_auc'),\n",
    "                                  return_train_score = True, refit='roc_auc', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd661df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[modelname] = eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe722f",
   "metadata": {},
   "source": [
    "### 9.6.4 Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2e5e950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RUSBoost1\n",
      "__________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Les meilleurs parameters sont:\n",
      "{'imputer__strategy': 'median', 'model__learning_rate': 0.75, 'model__n_estimators': 50}\n",
      "\n",
      "Le metric neg_log_loss donne :\n",
      "-0.69 +/-  0.00 pour le train sets\n",
      "-0.69 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.00\n",
      "\n",
      "Le metric roc_auc donne :\n",
      " 0.73 +/-  0.00 pour le train sets\n",
      " 0.72 +/-  0.00 pour le test sets\n",
      "test score / train score : 1.02\n",
      "\n",
      "Le temps d'entrainement est  108310.22 +/- 845.06 ms.\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_evaluation(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69b50f",
   "metadata": {},
   "source": [
    "# 10. Export du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "751d944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'LogRegr0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d574be7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\bookj\\\\Desktop\\\\DataScientist\\\\Projet7\\\\Data\\\\LogRegr2']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = model_dict[modelname]['estimator']\n",
    "joblib.dump(estimator, PATH + '\\\\Data\\\\' + modelname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
